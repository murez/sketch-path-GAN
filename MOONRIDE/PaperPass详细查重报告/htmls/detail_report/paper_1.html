<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="">
    <meta name="description" content="">
    <title>PaperPass 最权威论文抄袭检测系统</title>
    <link href="../css/bootstrap.css" rel="stylesheet" />
    <link href="../css/style.css" rel="stylesheet" />
</head>
<body>
<div>
    <div class="text-center PT30">
        <ul class="pagination"><li><a href="#"><span>首页</span></a></li>
    <li><a href="#"><span>上一页</span></a></li>
    <li><a href="paper_2.html"><span>下一页</span></a></li>
    <li><a href="paper_2.html"><span>尾页</span></a></li></ul>
    <div class="ML15 inline-block v-top MT10">
            页码
            <span class="g-font-color green">1</span>/<span>2</span>
            页
        </div>    </div>
    <div class="paper-txt P30 PB0">
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="1">1</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">基于成式对抗神经络的素描路径成系统张元 龚敬洋关键字:</span> <span class="g-font-color green"> 神经络;</span> <span class="g-font-color green">深度学习;</span> <span class="g-font-color green">成式对抗络;</span> <span class="g-font-color green">绘画格转移1.选题背景现在路上靡的相机滤镜都有素描画的图滤镜。</span> <span class="g-font-color green">同时在执法和刑事案件中嫌疑的素描画任然作为击者提供线索的重要依据。</span> <span class="g-font-color green">在娱乐和社会安全两都有对素描画像的需要。</span> <span class="g-font-color green">但素描价格昂贵，产效率低，而普通基于图简单滤镜变换的素描画真实度不，通常伴有不合适的线条或低清晰度，同时笔画线条不清楚。</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="2">2</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">最近GAN(Generative Adversarial Networks)[1] 和CNN(convolutional neural network)等神经络技术的发展，直接产量素描笔画路径的机器算法成为可能。</span> <span class="g-font-color green">本将介绍我们利GAN技术提出的素描路径成系统的算法和框架，并进详细的实验证明和与普通滤镜素描成器和绘画的结果较和改进案。</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="3">3</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">2.相关作基于神经络算法的发展和 CUDA( Compute Unied Device Architecture)显卡计算技术的发展，</span> <span class="g-font-color green">原先许多必须由成图像合成算法现在可以通过神经络得出我们想要的模型。</span> <span class="g-font-color green">而2014年Ian Goodfellow等提出的GAN(Generative Adversarial Networks)进步实现了神经络在图像处理上的进步发展。</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="4">4</span>
            <p class="MT20 text-idt25" tpl-section="text">
                <a href='../sentence_detail/13.html' target='right' class='g-font-color orange'>3.我们的法想象阿尔布雷希特丢勒( Albrecht Drer，1471－1528)师在艺复兴时期对铜镜中的画出了世界上第幅画像，</a> <span class="g-font-color green">他的铅笔线条柔和流畅明暗中的栩栩如，如果丢勒来到现在的城市公园，为富有年轻活的少画画像会怎么样？</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="5">5</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">1.回归素描绘画过程普通的机器滤镜实现的主要原理都是由基于图灰度特征或者卷积计算后得到特征，</span> <span class="g-font-color green">而在绘画中恰恰不会开始就从整体的调或者从整体描画出图像。</span> <span class="g-font-color green">通过模仿类艺术创作的过程实现机器进艺术创作的效果会明显简单机器滤镜的效果要好很多，</span> <span class="g-font-color green"> Combining Sketch and Tone for Pencil Drawing Production[2]通过绘画主体的描绘和背景的描绘拆分实现了机器素描绘画的最效果，</span> <span class="g-font-color green">所以我们回归到类像的素描绘画过程中，实现更好的结果。</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="6">6</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">我们考虑位素描艺术家看到了张脸(感谢陈同学的出镜)陈同学他会考虑物的脸型轮廓，</span> <span class="g-font-color green">五官位置和形状，头发式样，光线强弱......所以我们就需要根据图提取这些特征。</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="7">7</span>
            <p class="MT20 text-idt25" tpl-section="text">
                <a href='../sentence_detail/22.html' target='right' class='g-font-color orange'>3.模型建1.模型结构本节将详细阐述解决法，并提供详细的模型案。</a> <span class="g-font-color green">主要模型分为脸信息提取和神经络模型的设计与搭建。</span> <span class="g-font-color green">先由原图像提取脸信息，随后将脸信息和图像起作为数据集输模型，最后输出素描路径。</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="8">8</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">2.公式给定由 表原图像和草图的数据集。</span> <span class="g-font-color green">我们的的是让模型学习两个函数 和代表照到素描的成器和素描到照的成器。</span> <span class="g-font-color green">我们考虑这是个图像到图像的翻译作，我们使 CycleGAN[此处有论]，</span> <span class="g-font-color green">假设两个络和两个神经络成器分别代表代表照到素描的成器和素描到照的成器。</span> <span class="g-font-color green"> 以真图像 输，成 的素描路径；</span> <span class="g-font-color green"> 以素描路径 输，成 的真图像。</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="9">9</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">所以图像转化为素描的过程可以表为：</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="10">10</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">3.脸特征信息提取1、脸识别 API的选择祥洁敫宁耀 API</span> <span class="g-font-color green">名称平均响应时间关键点数量免费调流量限制百度云315 ms722 QPS旷视 FACE</span> <span class="g-font-color green">+</span> <span class="g-font-color green">+206 ms106不限量，</span> <span class="g-font-color green">与其他共享 QPS池腾讯294 ms881万张/原图小原图体积压缩后图小压缩后</span> <span class="g-font-color green">图体积4288*28483.01 MB1500*995554 kb6000*40006.15 MB1500*</span> <span class="g-font-color green">1000682 kb2048*20482.18 MB2048*2048325 kb将肖像照转化为素描照，</span> <span class="g-font-color green">先需要提取照中脸中相关特征点的位置，以便后续的 GAN络成素描画。</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="11">11</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">前互联上提供了量已训练成熟的基于 CNN( convolutional neural network)的部识别 API可供调，</span> <span class="g-font-color green">但它们在响应时间，部关键点数量和调流量计费式上均有差异。</span> <span class="g-font-color green">通过对国内三款主流部识别服务供应商提供的API进量测试，基本可以得出三款API的相关差异。</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="12">12</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">由上表可知，对于小规模部识别调而，FACE++[3]在关键点数量及响应时间上相其他两款API均有明显优势。</span> <span class="g-font-color green">因此本中我们将选择该API进脸特征信息的提取。</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="13">13</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">2、图预处理旷视 FACE++对于上传图有最40964096像素，2 MB件小的限制要求，</span> <span class="g-font-color green">而前绝多数拍摄设备拍出的图件参数均于该值，同时为了减少因进脸识别而产的流量，</span> <span class="g-font-color green">需要先对图进适当压缩和 s缩放。</span> <span class="g-font-color green">我们先将图进适当锐化以保证其不因缩放导致锐度下降，进而影响识别成功率。</span> <span class="g-font-color green">随后通过OpenCV[4]图像压缩算法对件体积进适当压缩，并对图进等例缩放以保证其小和体积被控制在合理范围内。</span> <span class="g-font-color green">为了防图缩小时出现波纹，我们使了像素关系重采样的式(CV_INTER_AREA)对图进缩放。</span> <span class="g-font-color green">具体函数法如下：</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="14">14</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">经过测试，处理后图像的件体积已基本被控制在可接受范围内。</span> <span class="g-font-color green">测试数据如下：</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="15">15</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">3、获得脸特征信息将照进预处理后，我们通过POST式调旷世FACE++的部识别接口，并获得包含脸特征信息的JSON数据。</span> <span class="g-font-color green">获得的脸特征信息包含部的矩形位置(face_rectangle)，部器官的轮廓位置(landmarks)以及脸的特征信息(attributes)。</span> <span class="g-font-color green">通过对JSON数据进解析和分离，便可得到精确的脸特征点位置信息。</span> <span class="g-font-color green">测试结果如下：</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="16">16</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">#通过 CV_ INTER_ AREA法缩放图标小 cv2. resize( SourceImage，</span> <span class="g-font-color green">( DXsize， DYsize)， interpolation= cv2. INTER_ AREA)#适当降低照质量以减小图质量 cv2. imwrite( TargetFileName，</span> <span class="g-font-color green"> SourceImage，[ int( cv2. IMWRITE_ JPEG_ QUALITY)，</span> <span class="g-font-color green"> QualityKeepValue])图3-1原图(图3-2识别结果( face_ rectangle))(</span> <span class="g-font-color green">图3-2识别结果( landmarks))输出的数据是物轮廓的内容和点阵位置，</span> <span class="g-font-color green">这就是先把握物的整体形象。</span> <span class="g-font-color green">这部分作为脸特征信息，设其为 。</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="17">17</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">3.模型设计cycleGAN[5]是种不成对的图像到图像转换的神经络算法，由Berkeley AI Research (BAIR) laboratory， UCBerkeley在2018年提出。</span> <span class="g-font-color green"> 算法主要基于GAN成式对抗络算法。</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="18">18</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">该算法的原理可以概述为：</span> <span class="g-font-color green">将A格图转换成B格图[6]。</span> <span class="g-font-color green">也就是说，现在有两个样本空间(sample space)，和 我们希望把 空间中的样本通过cycleGAN转换成 空间中的样本。</span> <span class="g-font-color green">所以我们的的就是拟合学习个成器或映射，设这个映射为，则它就对应着 GAN中的成器( Generator)，</span><a href='../sentence_detail/71.html' target='right' class='g-font-color orange'> F可以将 X中的样本空间 x映射到 Y的样本空间中。</a> <span class="g-font-color green">对于成的图，我们还需要 GAN中的鉴别器( Discriminator)来区分它是否为理想图，</span> <span class="g-font-color green">即为我们所希望要的图，由此建 GAN( Generative Adversarial Networks)。</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
        
        <div class="paper-section" tpl-section="warp">
            <span class="label-warning" tpl-section="badge" data-id="19">19</span>
            <p class="MT20 text-idt25" tpl-section="text">
                 <span class="g-font-color green">正如在讨论中[7]， 这些伪影是由于已知的训练不稳 定性而产的，同时产分辨率图像。</span> <span class="g-font-color green"> 这些不稳定 性可能是由于然图像分布和隐含模型分布的持可 能在维空间中不重叠的事实。</span> <span class="g-font-color green"> 这个问题的严重性随 着图像分辨率的增加而增加。</span> <span class="g-font-color green"> 因此，为了在成逼真 图像时避免这些伪像，我们提出了个逐级多尺度优 化框架，通过利成器络中不同分辨率的特征 映射的隐式存在。</span> <span class="g-font-color green"> 考虑到多数GAN框架具有与编码 器 - 解码器类型相似的成器，其中具有堆卷积和 最池化层，随后是系列解卷积层。</span><a href='../sentence_detail/79.html' target='right' class='g-font-color orange'> 反卷积层将特 征映射从较低分辨率顺序上采样到较分辨率。</a> <span class="g-font-color green"> 来 每个解卷积层的特征图都是通过33卷积层转发以成不同分辨率的输出图像。</span>            </p>
            <div class="text-right">
                <button type="button" tpl-section="btn" class="g-btn g-btn-default g-btn-sm MT10">段落修改</button>
            </div>
            <div tpl-section="box"></div>
        </div>
            </div>
    <div class="text-center PB30">
        <ul class="pagination"><li><a href="#"><span>首页</span></a></li>
    <li><a href="#"><span>上一页</span></a></li>
    <li><a href="paper_2.html"><span>下一页</span></a></li>
    <li><a href="paper_2.html"><span>尾页</span></a></li></ul>
    <div class="ML15 inline-block v-top MT10">
            页码
            <span class="g-font-color green">1</span>/<span>2</span>
            页
        </div>    </div>
    <div style="text-align: center;padding-top:30px">
         <a href="http://www.118qikan.com/service?f=pp_report_section" target="_blank"><img src="http://file.paperpass.com/images/fabiao.jpg"/></a></div>
    <div class="paper-footer">
        <p>检测报告由<a href="http://www.paperpass.com/" target="_blank">PaperPass</a>文献相似度检测系统生成</p>
        <p>Copyright © 2007-2018 PaperPass</p>
    </div>
</div>
</body>
<script type="text/html" template="section">
    <div class="text-right">
        <div class="modifyTxt-notice">
            修改完本段落之后，点击“临时保存”，之后可在上方导航“修改文档”页面中查看修改后的内容
        </div>
        <textarea class="form-control resize-none" rows="4" tpl-section="textarea"></textarea>
        <div class="button-wrap MT10">
            <button type="button" class="g-btn g-btn-default g-btn-sm red" tpl-section-cancle="btn">取消保存</button>
            <button type="button" class="g-btn g-btn-default g-btn-sm" tpl-section-save="btn">临时保存</button>
        </div>
    </div>
</script>
<script type="text/javascript" src="../js/jquery.min.js"></script>
<script type="text/javascript" src="../js/Lib.js"></script>
<script type="text/javascript">
    Report.report_id = '5b439a33d1086hfmu';
</script>
<script type="text/javascript">
    (function(System,$){

        var sectionEdit = System.Paper.sectionEdit();
        var sectionSave = System.Paper.sectionSave(null);
        $(function(){
            $(document).on('click','[tpl-section=btn]',function(){
                sectionEdit.call(this);
            });
            $(document).on('click','[tpl-section-save=btn]',function(){
                sectionSave.call(this);

            });
            $(document).on('click','[tpl-section-cancle=btn]',function(){
                var $warp = $(this).closest('[tpl-section="warp"]');
                $warp.find('[tpl-section="box"]').html('');
            });


        });
    })(Report,jQuery);

</script>
</html>