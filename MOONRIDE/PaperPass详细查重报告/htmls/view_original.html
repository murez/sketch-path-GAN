<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="">
    <meta name="description" content="">
    <title>查看原文</title>
    <link href="css/bootstrap.css" rel="stylesheet" />
    <link href="css/style.css" rel="stylesheet" />
</head>
<body>
<div class="bg-grey PLR40">

    <div class="paper-txt P30">
        <p class="text-idt25" data-id="1">基于成式对抗神经络的素描路径成系统张元 龚敬洋关键字: 神经络;深度学习;成式对抗络;绘画格转移1.选题背景现在路上靡的相机滤镜都有素描画的图滤镜。同时在执法和刑事案件中嫌疑的素描画任然作为击者提供线索的重要依据。在娱乐和社会安全两都有对素描画像的需要。但素描价格昂贵，产效率低，而普通基于图简单滤镜变换的素描画真实度不，通常伴有不合适的线条或低清晰度，同时笔画线条不清楚。</p><p class="text-idt25" data-id="2">最近GAN(Generative Adversarial Networks)[1] 和CNN(convolutional neural network)等神经络技术的发展，直接产量素描笔画路径的机器算法成为可能。本将介绍我们利GAN技术提出的素描路径成系统的算法和框架，并进详细的实验证明和与普通滤镜素描成器和绘画的结果较和改进案。</p><p class="text-idt25" data-id="3">2.相关作基于神经络算法的发展和 CUDA( Compute Unied Device Architecture)显卡计算技术的发展，原先许多必须由成图像合成算法现在可以通过神经络得出我们想要的模型。而2014年Ian Goodfellow等提出的GAN(Generative Adversarial Networks)进步实现了神经络在图像处理上的进步发展。</p><p class="text-idt25" data-id="4">3.我们的法想象阿尔布雷希特丢勒( Albrecht Drer，1471－1528)师在艺复兴时期对铜镜中的画出了世界上第幅画像，他的铅笔线条柔和流畅明暗中的栩栩如，如果丢勒来到现在的城市公园，为富有年轻活的少画画像会怎么样？</p><p class="text-idt25" data-id="5">1.回归素描绘画过程普通的机器滤镜实现的主要原理都是由基于图灰度特征或者卷积计算后得到特征，而在绘画中恰恰不会开始就从整体的调或者从整体描画出图像。通过模仿类艺术创作的过程实现机器进艺术创作的效果会明显简单机器滤镜的效果要好很多， Combining Sketch and Tone for Pencil Drawing Production[2]通过绘画主体的描绘和背景的描绘拆分实现了机器素描绘画的最效果，所以我们回归到类像的素描绘画过程中，实现更好的结果。</p><p class="text-idt25" data-id="6">我们考虑位素描艺术家看到了张脸(感谢陈同学的出镜)陈同学他会考虑物的脸型轮廓，五官位置和形状，头发式样，光线强弱......所以我们就需要根据图提取这些特征。</p><p class="text-idt25" data-id="7">3.模型建1.模型结构本节将详细阐述解决法，并提供详细的模型案。主要模型分为脸信息提取和神经络模型的设计与搭建。先由原图像提取脸信息，随后将脸信息和图像起作为数据集输模型，最后输出素描路径。</p><p class="text-idt25" data-id="8">2.公式给定由 表原图像和草图的数据集。我们的的是让模型学习两个函数 和代表照到素描的成器和素描到照的成器。我们考虑这是个图像到图像的翻译作，我们使 CycleGAN[此处有论]，假设两个络和两个神经络成器分别代表代表照到素描的成器和素描到照的成器。 以真图像 输，成 的素描路径； 以素描路径 输，成 的真图像。</p><p class="text-idt25" data-id="9">所以图像转化为素描的过程可以表为：</p><p class="text-idt25" data-id="10">3.脸特征信息提取1、脸识别 API的选择祥洁敫宁耀 API名称平均响应时间关键点数量免费调流量限制百度云315 ms722 QPS旷视 FACE++206 ms106不限量，与其他共享 QPS池腾讯294 ms881万张/原图小原图体积压缩后图小压缩后图体积4288*28483.01 MB1500*995554 kb6000*40006.15 MB1500*1000682 kb2048*20482.18 MB2048*2048325 kb将肖像照转化为素描照，先需要提取照中脸中相关特征点的位置，以便后续的 GAN络成素描画。</p><p class="text-idt25" data-id="11">前互联上提供了量已训练成熟的基于 CNN( convolutional neural network)的部识别 API可供调，但它们在响应时间，部关键点数量和调流量计费式上均有差异。通过对国内三款主流部识别服务供应商提供的API进量测试，基本可以得出三款API的相关差异。</p><p class="text-idt25" data-id="12">由上表可知，对于小规模部识别调而，FACE++[3]在关键点数量及响应时间上相其他两款API均有明显优势。因此本中我们将选择该API进脸特征信息的提取。</p><p class="text-idt25" data-id="13">2、图预处理旷视 FACE++对于上传图有最40964096像素，2 MB件小的限制要求，而前绝多数拍摄设备拍出的图件参数均于该值，同时为了减少因进脸识别而产的流量，需要先对图进适当压缩和 s缩放。我们先将图进适当锐化以保证其不因缩放导致锐度下降，进而影响识别成功率。随后通过OpenCV[4]图像压缩算法对件体积进适当压缩，并对图进等例缩放以保证其小和体积被控制在合理范围内。为了防图缩小时出现波纹，我们使了像素关系重采样的式(CV_INTER_AREA)对图进缩放。具体函数法如下：</p><p class="text-idt25" data-id="14">经过测试，处理后图像的件体积已基本被控制在可接受范围内。测试数据如下：</p><p class="text-idt25" data-id="15">3、获得脸特征信息将照进预处理后，我们通过POST式调旷世FACE++的部识别接口，并获得包含脸特征信息的JSON数据。获得的脸特征信息包含部的矩形位置(face_rectangle)，部器官的轮廓位置(landmarks)以及脸的特征信息(attributes)。通过对JSON数据进解析和分离，便可得到精确的脸特征点位置信息。测试结果如下：</p><p class="text-idt25" data-id="16">#通过 CV_ INTER_ AREA法缩放图标小 cv2. resize( SourceImage，( DXsize， DYsize)， interpolation= cv2. INTER_ AREA)#适当降低照质量以减小图质量 cv2. imwrite( TargetFileName， SourceImage，[ int( cv2. IMWRITE_ JPEG_ QUALITY)， QualityKeepValue])图3-1原图(图3-2识别结果( face_ rectangle))(图3-2识别结果( landmarks))输出的数据是物轮廓的内容和点阵位置，这就是先把握物的整体形象。这部分作为脸特征信息，设其为 。</p><p class="text-idt25" data-id="17">3.模型设计cycleGAN[5]是种不成对的图像到图像转换的神经络算法，由Berkeley AI Research (BAIR) laboratory， UCBerkeley在2018年提出。 算法主要基于GAN成式对抗络算法。</p><p class="text-idt25" data-id="18">该算法的原理可以概述为：将A格图转换成B格图[6]。也就是说，现在有两个样本空间(sample space)，和 我们希望把 空间中的样本通过cycleGAN转换成 空间中的样本。所以我们的的就是拟合学习个成器或映射，设这个映射为，则它就对应着 GAN中的成器( Generator)， F可以将 X中的样本空间 x映射到 Y的样本空间中。对于成的图，我们还需要 GAN中的鉴别器( Discriminator)来区分它是否为理想图，即为我们所希望要的图，由此建 GAN( Generative Adversarial Networks)。</p><p class="text-idt25" data-id="19">正如在讨论中[7]， 这些伪影是由于已知的训练不稳 定性而产的，同时产分辨率图像。 这些不稳定 性可能是由于然图像分布和隐含模型分布的持可 能在维空间中不重叠的事实。 这个问题的严重性随 着图像分辨率的增加而增加。 因此，为了在成逼真 图像时避免这些伪像，我们提出了个逐级多尺度优 化框架，通过利成器络中不同分辨率的特征 映射的隐式存在。 考虑到多数GAN框架具有与编码 器 - 解码器类型相似的成器，其中具有堆卷积和 最池化层，随后是系列解卷积层。 反卷积层将特 征映射从较低分辨率顺序上采样到较分辨率。 来 每个解卷积层的特征图都是通过33卷积层转发以成不同分辨率的输出图像。</p><p class="text-idt25" data-id="20">整个络结构如上图所。通过构建多重成式对抗神经络，在隐藏层中也添加判断器减少伪像的产，不过最终还是需要通过像素之间的较判断图成效果，所以我们使 openCV中的函数将路径(量图)转换成为像素图像进较。</p><p class="text-idt25" data-id="21">所以在三个节点构造层我们有的输出，分别通过3个判别器，而作为最后个图像将继续传递到下个络中，最终的产的两张原图像，就是最终的还原脸图像，这两张图像分别加判别器。</p><p class="text-idt25" data-id="22">综合模型我们可以得出模型的损失函数：</p><p class="text-idt25" data-id="23">训练的标就是 且 。为了使成的图像更加接近我们的标，我们需要使成差 最小。 可以被定义为：除了 减小差距，还通过在不同分辨率阶段引 来实现减少了可能的映射函数的空间过多出现的伪像，其定义如下：</p><p class="text-idt25" data-id="24">综上标损失函数即为：</p><p class="text-idt25" data-id="25">4.实验结果所提出的法在现有的查看草图数据集上进评估。中脸部素描数据库（ CUFS）[8]是个观看素描数据库，其中包括来港中学（ CUHK）学数据库的188张孔，来 AR数据库的123张孔[9]，以及来 XM2 VTS数据库的295个脸[10].对于每张脸，都有张艺术家根据在正常照明条件下以正姿势拍摄的照以及中性表情绘制的草图。</p><p class="text-idt25" data-id="26">经过训练最终的结果：</p><p class="text-idt25" data-id="27">PnVhvT.png最后放上陈同学经过我们的模型后产的肖像画。</p><p class="text-idt25" data-id="28">5.参考献[1] Ian， J， Goodfellow， Jean， Pouget- Abadie， Mehdi， Mirza， Bing， Xu， David， Warde- Farley， Sherjil， Ozair， Aaron， Courville， Yoshua， Bengio. Generative Adversarial Networks[C]. arXiv:1406.2661v1:Ian J. Goodfellow， JeanPouget-Abadie， Mehdi Mirza， Bing Xu， David Warde-Farley， Sherjil Ozair， Aaron Courville， Yoshua Bengio，2014.</p><p class="text-idt25" data-id="29">[2] ewu， Lu， Li， Xu， Jiaya， Jia. Combining Sketch and Tone for Pencil Drawing Production[C]. The ChineseUniversity of Hong Kong:Cewu Lu Li Xu Jiaya Jia， 2012.</p><p class="text-idt25" data-id="30">[3] face++[EB/OL]. https://www.faceplusplus.com.cn/.</p><p class="text-idt25" data-id="31">[4] OpenCV[EB/OL]. https://opencv.org/.</p><p class="text-idt25" data-id="32">[5] Jun-Yan， Zhu， Taesung， Park， Phillip， Isola， Alexei， A， Efros. Unpaired Image-to-Image Translation usingCycle-Consistent Adversarial Networks[C]. arXiv:1703.10593:Jun-Yan Zhu， Taesung Park， Phillip Isola， AlexeiA. Efros， 2018.</p><p class="text-idt25" data-id="33">[6] 学酱. 可能是近期最好玩的深度学习模型：CycleGAN的原理与实验详解[EB/OL]. https://yq.aliyun.com/articles/229300.</p><p class="text-idt25" data-id="34">[7] H. Zhang， T. Xu， H. Li， S. Zhang， X. Huang， X. Wang， and D. Metaxas. Stackgan: Text to photo-realisticimage synthesis with stacked generative adversarial networks[C]. In IEEE ICCV， 2017.</p><p class="text-idt25" data-id="35">[8] X. Wang and X. Tang. Face photo-sketch synthesis and recognition. TPAMI， 31(11):19551967， 2009.</p><p class="text-idt25" data-id="36">[9] A. Martinez and R. Benavente. The ar face database， cvc. 1998.</p><p class="text-idt25" data-id="37">[10] K. Messer， J. Matas， J. Kittler， J. Luettin， and G. Maitre. Xm2vtsdb: The extended m2vts database. InSecond international conference on audio and video-based biometric person authentication， volume 964，pages 965966， 1999.</p>        <div class="paper-footer">
            <p>检测报告由<a href="http://www.paperpass.com/" target="_black">PaperPass</a>文献相似度检测系统生成</p>
            <p>Copyright © 2007-2018 PaperPass</p>
        </div>
    </div>

</div>
</body>
</html>
